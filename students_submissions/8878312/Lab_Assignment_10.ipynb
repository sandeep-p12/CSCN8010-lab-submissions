{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Assignment 10: <br>\n",
    "### Student Name: Sandeep Pandey\n",
    "### Student ID: 8878312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment targets to assure that the students understood basic IR concepts.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Implementing an IR System (10/16)**<br>\n",
    "\n",
    "Consider a collection of 1000 documents and a set of 10 queries. Implement an IR system based on the Vector Space Model (VSM) using TF-IDF weighting.<br>\n",
    "\n",
    "Dataset:<br>\n",
    "\n",
    "- 1000 documents (text content for each document)\n",
    "- 10 sample queries <br>\n",
    "IR System:<br>\n",
    "\n",
    "Implement TF-IDF calculation for document-term matrix construction. <br>\n",
    "Develop a cosine similarity-based retrieval system to rank documents for each query. <br>\n",
    "Rank the top 10 documents for each query using the IR system. <br>\n",
    "Evaluation: <br>\n",
    "\n",
    "Compute Precision at k (P@k) for k=5, k=6, and k=10 for each query.<br>\n",
    "Calculate Mean Average Precision (MAP) across all queries. <br>\n",
    "Calculate the Mean Reciprocal Rank (MRR) across all queries.(3) <br><br>\n",
    "**Part 2: Assessing Inter-Annotator Agreement (6/16)**<br>\n",
    "\n",
    "Given the relevance assessments by three different annotators for a set of documents:<br>\n",
    "\n",
    "Annotator 1,2 and 3 relevance assessments<br>\n",
    "\n",
    "You are expected to: <br>\n",
    "\n",
    "Compute pairwise Cohen's Kappa values for the annotators' relevance assessments.<br>\n",
    "Discuss the observed agreement levels among annotators.<br>\n",
    "Explain how to improve the kappa value if we are not satisfied with the kappa.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------\n",
    "- Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"Machine learning is transforming various industries.\",\n",
    "    \"Natural language processing helps in text analysis.\",\n",
    "    \"AI algorithms can improve decision-making processes.\",\n",
    "    \"Data science involves extracting insights from data.\",\n",
    "    \"Robotics is a field combining hardware and software.\",\n",
    "    \"Deep learning models require large amounts of data.\",\n",
    "    \"Blockchain technology secures digital transactions.\",\n",
    "    \"Cloud computing offers scalable computing power.\",\n",
    "    \"Virtual reality provides immersive experiences.\",\n",
    "    \"Augmented reality enhances real-world environments.\",\n",
    "    \"Internet of Things connects devices for data exchange.\",\n",
    "    \"Biometric authentication ensures secure access.\",\n",
    "    \"Quantum computing promises faster computations.\",\n",
    "    \"Cybersecurity protects against digital threats.\",\n",
    "    \"Ethical considerations in AI development are crucial.\",\n",
    "    \"Healthcare benefits from AI-driven diagnostics.\",\n",
    "    \"E-commerce relies on personalized recommendation systems.\",\n",
    "    \"Autonomous vehicles revolutionize transportation.\",\n",
    "    \"Smart cities utilize IoT for efficient operations.\",\n",
    "    \"Social media analysis aids in understanding trends.\",\n",
    "    \"Predictive analytics anticipates future outcomes.\",\n",
    "    \"Remote work trends increase reliance on digital tools.\",\n",
    "    \"Energy efficiency through smart grids is vital.\",\n",
    "    \"Fintech innovations reshape financial services.\",\n",
    "    \"Data privacy concerns arise in the era of big data.\",\n",
    "    \"Artificial general intelligence remains a challenge.\",\n",
    "    \"Human-computer interaction shapes user experiences.\",\n",
    "    \"Big data analytics drives informed decision-making.\",\n",
    "    \"Climate change predictions benefit from AI models.\",\n",
    "    \"Bioinformatics applies computational techniques to biology.\",\n",
    "    \"Robotic process automation streamlines workflows.\",\n",
    "    \"Industry 4.0 integrates AI with manufacturing.\",\n",
    "    \"Sentiment analysis detects emotions in text data.\",\n",
    "    \"Reinforcement learning powers autonomous agents.\",\n",
    "    \"Data visualization simplifies complex information.\",\n",
    "    \"Edge computing reduces latency in data processing.\",\n",
    "    \"Smart farming optimizes agricultural practices.\",\n",
    "    \"AI in education enhances personalized learning.\",\n",
    "    \"Natural disaster predictions leverage machine learning.\",\n",
    "    \"Media recommendation systems personalize content.\",\n",
    "    \"Speech recognition enables hands-free interactions.\",\n",
    "    \"Genetic algorithms mimic natural selection.\",\n",
    "    \"Neural networks simulate the human brain.\",\n",
    "    \"Behavioral analytics uncovers patterns in behavior.\",\n",
    "    \"Spatial analysis benefits from geospatial data.\",\n",
    "    \"Explainable AI improves transparency in models.\",\n",
    "    \"AI ethics guide responsible technology development.\",\n",
    "    \"Prescriptive analytics offers actionable insights.\",\n",
    "    \"Supply chain optimization employs predictive models.\",\n",
    "    \"Emotion AI detects emotions in facial expressions.\",\n",
    "    \"Distributed ledger technology ensures secure transactions.\",\n",
    "    \"Biological data analysis aids in medical research.\",\n",
    "    \"Smart grid technology enhances energy distribution.\",\n",
    "    \"AI-powered chatbots automate customer support.\",\n",
    "    \"Machine translation breaks language barriers.\",\n",
    "    \"Personalized medicine tailors treatments to individuals.\",\n",
    "    \"Data-driven marketing optimizes customer engagement.\",\n",
    "    \"Smart home devices enhance living experiences.\",\n",
    "    \"Time series forecasting predicts future trends.\",\n",
    "    \"AI-driven creativity challenges human capabilities.\",\n",
    "    \"Intelligent document processing automates data extraction.\",\n",
    "    \"Graph analytics explores relationships in networks.\",\n",
    "    \"Adversarial attacks pose challenges to AI security.\",\n",
    "    \"Predictive maintenance minimizes equipment downtime.\",\n",
    "    \"Spatial reasoning enhances AI navigation systems.\",\n",
    "    \"Privacy-preserving techniques protect sensitive data.\",\n",
    "    \"Automated decision-making raises ethical concerns.\",\n",
    "    \"Behavioral biometrics verifies user identities.\",\n",
    "    \"Explainable recommendations increase user trust.\",\n",
    "    \"Quantum machine learning explores quantum states.\",\n",
    "    \"Internet censorship detection uses AI techniques.\",\n",
    "    \"Smart wearables monitor health and fitness.\",\n",
    "    \"Intelligent tutoring systems adapt to student needs.\",\n",
    "    \"Graph neural networks model complex relationships.\",\n",
    "    \"AI in sports analytics improves performance analysis.\",\n",
    "    \"Facial recognition technology raises privacy debates.\",\n",
    "    \"Digital twin technology replicates physical systems.\",\n",
    "    \"Emotion detection in video content aids analysis.\",\n",
    "    \"Neuromorphic computing mimics brain structure.\",\n",
    "    \"Robotic surgery enhances precision in operations.\",\n",
    "    \"AI-powered language translation assists global communication.\",\n",
    "    \"Automated content moderation filters online content.\",\n",
    "    \"Network anomaly detection identifies security threats.\",\n",
    "    \"Predictive policing uses data to prevent crime.\",\n",
    "    \"Quantum cryptography ensures secure communications.\",\n",
    "    \"AI-generated art challenges traditional creativity.\",\n",
    "    \"Ethical considerations in autonomous vehicles are debated.\",\n",
    "    \"Adaptive learning systems personalize educational content.\",\n",
    "    \"Biomedical image analysis aids in disease diagnosis.\",\n",
    "    \"Explainable computer vision interprets image features.\",\n",
    "    \"AI-driven personalization enhances user experiences.\",\n",
    "    \"Conversational AI improves human-like interactions.\",\n",
    "    \"Federated learning protects individual data privacy.\",\n",
    "    \"Human-centered AI design prioritizes user needs.\",\n",
    "    \"Quantum annealing solves optimization problems.\",\n",
    "    \"Behavior-based authentication enhances security.\",\n",
    "    \"AI in music composition transforms creative processes.\",\n",
    "    \"Semantic search improves information retrieval.\",\n",
    "    \"Recommender systems optimize user preferences.\",\n",
    "    \"Information Retrieval systems are outdated without neural networks\"\n",
    "]\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What are the impacts of AI on healthcare?\",\n",
    "    \"How does machine learning improve financial services?\",\n",
    "    \"What is the role of AI in autonomous vehicles?\",\n",
    "    \"Explain the applications of natural language processing.\",\n",
    "    \"How does robotics benefit from AI integration?\",\n",
    "    \"What are the challenges in implementing AI in education?\",\n",
    "    \"How does data science contribute to climate change predictions?\",\n",
    "    \"What are the ethical considerations in AI development?\",\n",
    "    \"Explain the significance of AI in smart cities.\",\n",
    "    \"How does AI enhance cybersecurity measures?\"\n",
    "]\n",
    "print(len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "ground_truth =[[3, 74, 38, 92, 71, 72, 98, 48, 18, 100], \n",
    "                [12, 26, 52, 54, 21, 63, 64, 45, 14, 83],\n",
    "                [58, 77, 62, 31, 6, 61, 36, 96, 85, 18], \n",
    "                [99, 62, 98, 34, 63, 79, 43, 31, 3, 16],\n",
    "                [8, 88, 73, 82, 37, 25, 34, 87, 66, 58], \n",
    "                [90, 40, 84, 64, 34, 2, 73, 23, 59, 89],\n",
    "                [80, 10, 86, 21, 68, 37, 83, 57, 6, 98],\n",
    "                [22, 3, 2, 44, 56, 80, 50, 63, 87, 13],\n",
    "                [1, 18, 22, 44, 99, 72, 24, 95, 10, 87],\n",
    "                [31, 10, 56, 50, 75, 4, 18, 85, 84, 74]\n",
    "                           ]\n",
    "print(len(ground_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "doc_vectors = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def get_cosine_similarity(query):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    cosine_similarities = cosine_similarity(query_vector, doc_vectors).flatten()\n",
    "    return cosine_similarities\n",
    "\n",
    "# Retrieving and ranking documents for each query\n",
    "ranked_docs = []\n",
    "for query in queries:\n",
    "    cosine_similarities = get_cosine_similarity(query)\n",
    "    ranked_doc_indices = np.argsort(cosine_similarities)[::-1][:10]  # Top 10 documents\n",
    "    ranked_docs.append(ranked_doc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "def precision_at_k(ranked_list, ground_truth, k):\n",
    "    relevant_docs = set(ground_truth)\n",
    "    retrieved_docs = set(ranked_list[:k])\n",
    "    intersection = relevant_docs.intersection(retrieved_docs)\n",
    "    return len(intersection) / k\n",
    "\n",
    "def mean_average_precision(ranked_lists, ground_truths):\n",
    "    avg_precision_per_query = []\n",
    "    for ranked_list, ground_truth in zip(ranked_lists, ground_truths):\n",
    "        precisions = [precision_at_k(ranked_list, ground_truth, k) for k in range(1, len(ranked_list) + 1)]\n",
    "        avg_precision_per_query.append(np.mean(precisions))\n",
    "    return np.mean(avg_precision_per_query)\n",
    "\n",
    "def mean_reciprocal_rank(ranked_lists, ground_truths):\n",
    "    mrr = 0\n",
    "    for ranked_list, ground_truth in zip(ranked_lists, ground_truths):\n",
    "        for rank, doc in enumerate(ranked_list, 1):\n",
    "            if doc in ground_truth:\n",
    "                mrr += 1 / rank\n",
    "                break\n",
    "    return mrr / len(ranked_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics\n",
    "precision_k_values = [precision_at_k(ranked_docs[i], ground_truth[i], k) for i in range(len(queries)) for k in [5, 6, 10]]\n",
    "map_value = mean_average_precision(ranked_docs, ground_truth)\n",
    "mrr_value = mean_reciprocal_rank(ranked_docs, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.16666666666666666,\n",
       " 0.1,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.16666666666666666,\n",
       " 0.1,\n",
       " 0.2,\n",
       " 0.16666666666666666,\n",
       " 0.1,\n",
       " 0.2,\n",
       " 0.16666666666666666,\n",
       " 0.1,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4,\n",
       " 0.3333333333333333,\n",
       " 0.3,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0945, 0.19916666666666666)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_value, mrr_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "- Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is not relevant, 1 is relevant\n",
    "annotator1_relevance = [1, 0, 1, 0, 1, 1, 0, 0, 1, 0]  \n",
    "annotator2_relevance = [1, 1, 1, 0, 1, 0, 0, 1, 1, 1]  \n",
    "annotator3_relevance = [1, 0, 0, 0, 1, 0, 0, 1, 1, 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa between Annotator 1 and 2: 0.19999999999999996\n",
      "Cohen's Kappa between Annotator 1 and 3: 0.4\n",
      "Cohen's Kappa between Annotator 2 and 3: 0.44444444444444453\n"
     ]
    }
   ],
   "source": [
    "# Calculate pairwise Cohen's Kappa\n",
    "kappa_1_2 = cohen_kappa_score(annotator1_relevance, annotator2_relevance)\n",
    "kappa_1_3 = cohen_kappa_score(annotator1_relevance, annotator3_relevance)\n",
    "kappa_2_3 = cohen_kappa_score(annotator2_relevance, annotator3_relevance)\n",
    "\n",
    "# Print Kappa values\n",
    "print(f\"Cohen's Kappa between Annotator 1 and 2: {kappa_1_2}\")\n",
    "print(f\"Cohen's Kappa between Annotator 1 and 3: {kappa_1_3}\")\n",
    "print(f\"Cohen's Kappa between Annotator 2 and 3: {kappa_2_3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
